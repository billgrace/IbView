{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IbView1 Python3.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import sys\n",
    "import pdb\n",
    "import os\n",
    "import io\n",
    "import avro.datafile\n",
    "import avro.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IbDataLogger is logging data to (on Bill's MacBook Pro):\n",
    "\n",
    "    /Users/OneDrive - Entertel Technologies/SharedOneNote/LoggerLogs/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, just hardwire our path to the logged data\n",
    "DataFilePath = '/home/bill/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File names consist of two parts: a data descriptor and a logger suffix.\n",
    "\n",
    "\n",
    "The data descriptor for underlying data is:\n",
    "\n",
    "    'YYYY-MM-DD-Underlying'.\n",
    "    \n",
    "The data descriptor for an option is:\n",
    "\n",
    "    'SPX-YYYY-MM-DD-SSSS-CP-QueuedAtHH-mm-ss' where\n",
    "    YYYY-MM-DD is the expiration date,\n",
    "    SSSS is the strike price,\n",
    "    CP is CALL or PUT and\n",
    "    HH-mm-ss is the time at which this option was queued to be logged.\n",
    "\n",
    "The logger suffix is YYYYMMDD-HH.0.log where\n",
    "\n",
    "    YYYYMMDD is today's date and\n",
    "    HH is the hour (24 hour time) covered by this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files in the logged data directory\n",
    "DataFileDirectoryList = os.listdir(DataFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of file descriptors for sifting through the three kinds of files:\n",
    "\n",
    "1) Underlying data\n",
    "2) Option data\n",
    "3) Everything/anything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFileDescriptor(dict):\n",
    "    def __init__(self):\n",
    "        self['FileName'] = 'PlaceHolder'\n",
    "        self['LogHour'] = 6.0\n",
    "        self['LogDay'] = 1\n",
    "        self['LogMonth'] = 1\n",
    "        self['LogYear'] = 2018\n",
    "        self['FileType'] = 'Underlying'\n",
    "        self['StrikePrice'] = 2000\n",
    "        self['ExpirationYear'] = 2018\n",
    "        self['ExpirationMonth'] = 1\n",
    "        self['ExpirationDay'] = 1\n",
    "        self['ContractRight'] = 'CALL'\n",
    "        self['QueuedHour'] = 6.0\n",
    "        self['QueuedMinute'] = 1.0\n",
    "        self['QueuedSecond'] = 1.0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the list of file desciptors for the files in the logged data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underlying: 189, Option: 5864, Other: 0\n",
      "Underlying JSON files: 13, Option JSON files: 396\n"
     ]
    }
   ],
   "source": [
    "ListOfDataFileDescriptors = []\n",
    "NumberOfUnderlyingFiles = 0\n",
    "NumberOfUnderlyingJsonFiles = 0\n",
    "NumberOfOptionFiles = 0\n",
    "NumberOfOptionJsonFiles = 0\n",
    "NumberOfOtherFiles = 0\n",
    "for CurrentIndex in range(0, len(DataFileDirectoryList)-1):\n",
    "    CurrentFileDescriptor = DataFileDescriptor()\n",
    "    FileName = DataFileDirectoryList[CurrentIndex]\n",
    "    CurrentFileDescriptor['FileName'] = FileName\n",
    "    \n",
    "    # For now - just step over the JSON versions of the files\n",
    "    if FileName[4:8] == 'Json':\n",
    "        NumberOfOptionJsonFiles += 1\n",
    "        continue\n",
    "    if FileName[11:15] == 'Json':\n",
    "        NumberOfUnderlyingJsonFiles += 1\n",
    "        continue\n",
    "    # For now - just step over the JSON versions of the files\n",
    "        \n",
    "    if FileName[0:3] == 'SPX':\n",
    "        CurrentFileDescriptor['FileType'] = 'Option'\n",
    "        NumberOfOptionFiles += 1\n",
    "        CurrentFileDescriptor['StrikePrice'] = int(FileName[15:19])\n",
    "        CurrentFileDescriptor['ExpirationYear'] = int(FileName[4:8])\n",
    "        CurrentFileDescriptor['ExpirationMonth'] = int(FileName[9:11])\n",
    "        CurrentFileDescriptor['ExpirationDay'] = int(FileName[12:14])\n",
    "        if FileName[20] == 'P':\n",
    "            CurrentFileDescriptor['ContractRight'] = 'PUT'\n",
    "        else:        \n",
    "            CurrentFileDescriptor['ContractRight'] = 'CALL'\n",
    "        CurrentFileDescriptor['QueuedHour'] = int(FileName[-25:-23])\n",
    "        CurrentFileDescriptor['QueuedMinute'] = int(FileName[-22:-20])\n",
    "        CurrentFileDescriptor['QueuedSecond'] = int(FileName[-19:-17])\n",
    "    elif FileName[11:21] == 'Underlying':\n",
    "        CurrentFileDescriptor['FileType'] = 'Underlying'\n",
    "        NumberOfUnderlyingFiles += 1\n",
    "    else:\n",
    "        CurrentFileDescriptor['FileType'] = 'Other'\n",
    "        NumberOfOtherFiles += 1\n",
    "        continue\n",
    "    CurrentFileDescriptor['LogYear'] = int(FileName[-17:-13])\n",
    "    CurrentFileDescriptor['LogMonth'] = int(FileName[-13:-11])\n",
    "    CurrentFileDescriptor['LogDay'] = int(FileName[-11:-9])\n",
    "    CurrentFileDescriptor['LogHour'] = float(FileName[-8:-4])\n",
    "    ListOfDataFileDescriptors.append(CurrentFileDescriptor)\n",
    "print(f'Underlying: {str(NumberOfUnderlyingFiles)}, Option: {str(NumberOfOptionFiles)}, Other: {str(NumberOfOtherFiles)}')\n",
    "print(f'Underlying JSON files: {str(NumberOfUnderlyingJsonFiles)}, Option JSON files: {str(NumberOfOptionJsonFiles)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a single day and look at what's logged that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 264 files\n"
     ]
    }
   ],
   "source": [
    "MyYear = 2018\n",
    "MyMonth = 5\n",
    "MyDay = 9\n",
    "MyFiles = []\n",
    "for i in range(0, len(ListOfDataFileDescriptors)):\n",
    "    if (ListOfDataFileDescriptors[i]['LogYear'] == MyYear and\n",
    "    ListOfDataFileDescriptors[i]['LogMonth'] == MyMonth and\n",
    "    ListOfDataFileDescriptors[i]['LogDay'] == MyDay):\n",
    "        MyFiles.append(ListOfDataFileDescriptors[i])\n",
    "print('We got ' + str(len(MyFiles)) + ' files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort out the files logged that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 8 Underlying, \n",
      "256 Option and \n",
      "0 Other files.\n",
      "Underlying:\n",
      "2018-05-09-Underlying20180509-06.0.log\n",
      "2018-05-09-Underlying20180509-07.0.log\n",
      "2018-05-09-Underlying20180509-08.0.log\n",
      "2018-05-09-Underlying20180509-09.0.log\n",
      "2018-05-09-Underlying20180509-10.0.log\n",
      "2018-05-09-Underlying20180509-11.0.log\n",
      "2018-05-09-Underlying20180509-12.0.log\n",
      "2018-05-09-Underlying20180509-13.0.log\n",
      "Highest/Lowest strike price: 2710/2665\n",
      "Strike prices:\n",
      "[2665, 2670, 2675, 2680, 2685, 2690, 2695, 2700, 2705, 2710]\n"
     ]
    }
   ],
   "source": [
    "UnsortedUnderlyingFiles = []\n",
    "MyOptionFiles = []\n",
    "MyOtherFiles = []\n",
    "LowestStrikePrice = 999999\n",
    "HighestStrikePrice = 0\n",
    "for i in range(0, len(MyFiles)):\n",
    "    if MyFiles[i]['FileType'] == 'Underlying':\n",
    "        UnsortedUnderlyingFiles.append(MyFiles[i])\n",
    "    elif MyFiles[i]['FileType'] == 'Option':\n",
    "        MyOptionFiles.append(MyFiles[i])\n",
    "        if MyFiles[i]['StrikePrice'] > HighestStrikePrice:\n",
    "            HighestStrikePrice = MyFiles[i]['StrikePrice']\n",
    "        if MyFiles[i]['StrikePrice'] < LowestStrikePrice:\n",
    "            LowestStrikePrice = MyFiles[i]['StrikePrice']\n",
    "    else:\n",
    "        MyOtherFiles.append(MyFiles[i])\n",
    "MyUnderlyingFiles = sorted(UnsortedUnderlyingFiles, key=lambda filedescriptor: filedescriptor['LogHour'])\n",
    "MyStrikePrices = []\n",
    "for price in range(LowestStrikePrice, HighestStrikePrice + 1, 5):\n",
    "    MyStrikePrices.append(price)\n",
    "print('We got ' + str(len(MyUnderlyingFiles)) + ' Underlying, \\n' +\n",
    "                     str(len(MyOptionFiles)) + ' Option and \\n' +\n",
    "                     str(len(MyOtherFiles)) + ' Other files.')\n",
    "print('Underlying:')\n",
    "for i in range(0, len(MyUnderlyingFiles)):\n",
    "    print(MyUnderlyingFiles[i]['FileName'])\n",
    "print('Highest/Lowest strike price: ' + str(HighestStrikePrice) + '/' + str(LowestStrikePrice))\n",
    "print('Strike prices:')\n",
    "print(MyStrikePrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions for extracting data from the logged files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apogentus on stackoverflow\n",
    "def PrintException():\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print(f'Exception in ({filename}, line {lineno} \"{line.strip()}\"): {exc_obj}')\n",
    "    \n",
    "# (copied from older Python code's IbDataViewerUtilities.py)\n",
    "# Accept a string that was utf-8-encoded from a byte array and return the byte array from which the string was encoded\n",
    "def DecodeStringToBytes(String):\n",
    "    ReturnBytes = bytearray()\n",
    "    DecodeCounter = 0\n",
    "    DecodeValue = 0\n",
    "    CharNumber = 0\n",
    "    CharValue = 0\n",
    "    for Char in String:\n",
    "        CharValue = Char\n",
    "        CharNumber += 1\n",
    "        if DecodeCounter == 0:\n",
    "            # we're not currently in the process of converting 4 chars to a byte\n",
    "            if Char == '\\\\':\n",
    "                # this char may be the beginning of a 4-char set\n",
    "                DecodeCounter = 1\n",
    "                DecodeValue = 0\n",
    "            else:\n",
    "                # this char is just another char so add it to the byte array\n",
    "                ReturnBytes.append(ord(Char))\n",
    "        else:\n",
    "            if DecodeCounter == 1:\n",
    "                # This is the character following a backslash\n",
    "#                 if Char == 'x' or Char == 'X':\n",
    "                if Char == 'x':\n",
    "                    # it's the x of '\\xnn' so ignore it and move on to collect the two hex digits following\n",
    "                    DecodeCounter = 2\n",
    "#                 elif Char == 'a' or Char == 'A':\n",
    "#                 elif Char == 'a':\n",
    "#                     # it's the a of a 'Bell' ('\\a') so declare an ASCII BEL byte\n",
    "#                     ReturnBytes.append(7)\n",
    "#                     DecodeCounter = 0\n",
    "#                 elif Char == 'b' or Char == 'B':\n",
    "                elif Char == 'b':\n",
    "                    # it's the b of a backspace ('\\b') so declare an ASCII BS byte\n",
    "                    ReturnBytes.append(8)\n",
    "                    DecodeCounter = 0\n",
    "#                 elif Char == 't' or Char == 'T':\n",
    "                elif Char == 't':\n",
    "                    # it's the t of a tab ('\\t') so declare an ASCII TAB byte\n",
    "                    ReturnBytes.append(9)\n",
    "                    DecodeCounter = 0\n",
    "#                 elif Char == 'n' or Char == 'N':\n",
    "                elif Char == 'n':\n",
    "                    # it's the n of a newline ('\\n') so declare an ASCII LF byte\n",
    "                    ReturnBytes.append(10)\n",
    "                    DecodeCounter = 0\n",
    "#                 elif Char == 'v' or Char == 'V':\n",
    "                elif Char == 'v':\n",
    "                    # it's the v of a vertical tab ('\\v') so declare an ASCII VT byte\n",
    "                    ReturnBytes.append(11)\n",
    "                    DecodeCounter = 0\n",
    "#                 elif Char == 'f' or Char == 'F':\n",
    "                elif Char == 'f':\n",
    "                    # it's the f of a form feed ('\\f') so declare an ASCII FF byte\n",
    "                    ReturnBytes.append(12)\n",
    "                    DecodeCounter = 0\n",
    "#                 elif Char == 'r' or Char == 'R':\n",
    "                elif Char == 'r':\n",
    "                    # it's the r of a carriage return ('\\r') so declare an ASCII CR byte\n",
    "                    ReturnBytes.append(13)\n",
    "                    DecodeCounter = 0\n",
    "                elif Char == '\"':\n",
    "                    # it's the double quote of an escaped double quote so declare an ASCII double quote character code byte\n",
    "                    ReturnBytes.append(34)\n",
    "                    DecodeCounter = 0\n",
    "                elif Char == '\\'':\n",
    "                    # it's the single quote of an escaped single quote so declare an ASCII single quote character code byte\n",
    "                    ReturnBytes.append(39)\n",
    "                    DecodeCounter = 0\n",
    "                    # Perhaps the initial/original avro encoding does NOT escape a lone backslash character???\n",
    "                    # ... so a second backslash means the first one was just an ASCII backslash and this second\n",
    "                    # ... one is an escape character???\n",
    "                elif Char == '\\\\':\n",
    "#                         # it's the second backslash of an escaped backslash character so declare an ASCII backslash byte\n",
    "#                         ReturnBytes.append(92)\n",
    "#                         DecodeCounter = 0\n",
    "                    # it's a second backslash so append the first one as an actual slash and start the decode over\n",
    "                    ReturnBytes.append(ord('\\\\'))\n",
    "                    DecodeCounter = 1\n",
    "                else:\n",
    "#                         #else we got a not-yet-known escaped sequence so\n",
    "#                         print('\\nGot {0} after a backslash'.format(Char))\n",
    "#                         ReturnBytes.append(ord('\\\\'))\n",
    "#                         ReturnBytes.append(ord(Char))\n",
    "#                         DecodeCounter = 0\n",
    "                    # this character isn't know as an escape sequence's 2nd character so assume the preceding\n",
    "                    # backslash was simply a backslash\n",
    "                    ReturnBytes.append(ord('\\\\'))\n",
    "                    ReturnBytes.append(ord(Char))\n",
    "                    DecodeCounter = 0\n",
    "            elif DecodeCounter == 2:\n",
    "                # this char is the MSB of the encoded value\n",
    "                DecodeValue = 16 * IntegerHexValue(Char)\n",
    "                DecodeCounter = 3\n",
    "            else:\n",
    "                # this char is the LSB of the encoded value\n",
    "                DecodeValue += IntegerHexValue(Char)\n",
    "                ReturnBytes.append(DecodeValue)\n",
    "                DecodeCounter = 0\n",
    "    if DecodeCounter == 1:\n",
    "        ReturnBytes.append(ord('\\\\'))\n",
    "    return ReturnBytes\n",
    "\n",
    "def IntegerHexValue(Char):\n",
    "    if Char == '0':\n",
    "        return 0\n",
    "    elif Char == '1':\n",
    "        return 1\n",
    "    elif Char == '2':\n",
    "        return 2\n",
    "    elif Char == '3':\n",
    "        return 3\n",
    "    elif Char == '4':\n",
    "        return 4\n",
    "    elif Char == '5':\n",
    "        return 5\n",
    "    elif Char == '6':\n",
    "        return 6\n",
    "    elif Char == '7':\n",
    "        return 7\n",
    "    elif Char == '8':\n",
    "        return 8\n",
    "    elif Char == '9':\n",
    "        return 9\n",
    "    elif Char == 'a':\n",
    "        return 10\n",
    "    elif Char == 'b':\n",
    "        return 11\n",
    "    elif Char == 'c':\n",
    "        return 12\n",
    "    elif Char == 'd':\n",
    "        return 13\n",
    "    elif Char == 'e':\n",
    "        return 14\n",
    "    elif Char == 'f':\n",
    "        return 15\n",
    "    elif Char == 'A':\n",
    "        return 10\n",
    "    elif Char == 'B':\n",
    "        return 11\n",
    "    elif Char == 'C':\n",
    "        return 12\n",
    "    elif Char == 'D':\n",
    "        return 13\n",
    "    elif Char == 'E':\n",
    "        return 14\n",
    "    elif Char == 'F':\n",
    "        return 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try reading the first underlying file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "b'\\x06SPX\\xc0\\x1f\\x02\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd0\\x0f\\n\\xd7\\xa3p\\xbd\\xe6\\xa4@\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf6(\\\\\\x8f\\xc2\\xe4\\xa4@\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\xd7\\xa3p\\xbd\\xe5\\xa4@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x141525878000\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xecQ\\xb8\\x1e\\x85\\xf6\\xa4@\\x85\\xebQ\\xb8\\x1e\\xe5\\xa4@\\xa4p=\\n\\xd7\\xdf\\xa4@\\xd8\\xf27^\\xc2b\\x0c\\xda\\xe5\\x1eC(7\\x08\\xe9G'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-efaa50efba09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvroByteStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatumReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Line: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLineNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' at time '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTimeStampString\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', has price at: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Last'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/datafile.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_block_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mdatum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatum_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatum_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, decoder)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader_schema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'record'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'request'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m       \u001b[0mfail_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cannot read unknown schema type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread_record\u001b[0;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[1;32m    724\u001b[0m       \u001b[0mreaders_field\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreaders_fields_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreaders_field\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m         \u001b[0mfield_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreaders_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0mread_record\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_utf8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread_utf8\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mthat\u001b[0m \u001b[0mmany\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0mof\u001b[0m \u001b[0mUTF\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0mcharacter\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \"\"\"\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0minput_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread_utf8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/avro/io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0minput_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: b'\\x06SPX\\xc0\\x1f\\x02\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd0\\x0f\\n\\xd7\\xa3p\\xbd\\xe6\\xa4@\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf6(\\\\\\x8f\\xc2\\xe4\\xa4@\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\xd7\\xa3p\\xbd\\xe5\\xa4@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x141525878000\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xecQ\\xb8\\x1e\\x85\\xf6\\xa4@\\x85\\xebQ\\xb8\\x1e\\xe5\\xa4@\\xa4p=\\n\\xd7\\xdf\\xa4@\\xd8\\xf27^\\xc2b\\x0c\\xda\\xe5\\x1eC(7\\x08\\xe9G'"
     ]
    }
   ],
   "source": [
    "%%capture captured\n",
    "FullPathFileName = DataFilePath + '/' + MyUnderlyingFiles[2]['FileName']\n",
    "FirstUnderlyingFile = open(FullPathFileName, 'rt')\n",
    "LineNumber = 0\n",
    "for Line in FirstUnderlyingFile:\n",
    "    LineNumber += 1\n",
    "    TimeStampString, AvroStringWithByteTags = Line.split('---')\n",
    "    AvroString = AvroStringWithByteTags[2:-2]\n",
    "    AvroByteArray = DecodeStringToBytes(AvroString)\n",
    "    AvroByteStream = io.BytesIO(AvroByteArray)\n",
    "#     if LineNumber == 84 or LineNumber == 104 or LineNumber == 114:\n",
    "    if False:\n",
    "        print('!!!###*** Line: ' + str(LineNumber))\n",
    "        print(TimeStampString)\n",
    "        print(AvroString)\n",
    "        print(AvroByteArray)\n",
    "    else:\n",
    "        reader = avro.datafile.DataFileReader(AvroByteStream, avro.io.DatumReader())\n",
    "        for datum in reader:\n",
    "            print('Line: ' + str(LineNumber) + ' at time ' + TimeStampString + ', has price at: ' + str(datum['Last']['Price']))\n",
    "        reader.close()\n",
    "    #         break\n",
    "    AvroByteStream.close()\n",
    "#     break\n",
    "FirstUnderlyingFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bill/SiftedData/JupyterCapture.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1551325bcbcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCaptureOutputFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/bill/SiftedData/JupyterCapture.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCaptureOutputFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mCaptureOutputFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bill/SiftedData/JupyterCapture.txt'"
     ]
    }
   ],
   "source": [
    "CaptureOutputFile = open('/home/bill/SiftedData/JupyterCapture.txt', 'wt')\n",
    "CaptureOutputFile.write(captured.stdout)\n",
    "CaptureOutputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
